{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning and Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifiers\n",
    "These classifiers constist of multiple models. Their predictions are compared and the final predicition is the most common one (<i>hard voting classifier</i>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;, LogisticRegression()),\n",
       "                             (&#x27;rf&#x27;, RandomForestClassifier()), (&#x27;svc&#x27;, SVC())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;, LogisticRegression()),\n",
       "                             (&#x27;rf&#x27;, RandomForestClassifier()), (&#x27;svc&#x27;, SVC())])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>svc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression()),\n",
       "                             ('rf', RandomForestClassifier()), ('svc', SVC())])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[(\"lr\", log_clf), (\"rf\", rnd_clf), (\"svc\", svm_clf)],\n",
    "    voting=\"hard\"\n",
    ")\n",
    "\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "RandomForestClassifier 0.88\n",
      "SVC 0.896\n",
      "VotingClassifier 0.904\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If each classifier uses predict_proba() method, we can use <i>soft voting</i>. Prediction will be done using the probabilities values - bigger probabilities will have bigger weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "RandomForestClassifier 0.896\n",
      "SVC 0.896\n",
      "VotingClassifier 0.92\n"
     ]
    }
   ],
   "source": [
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC(probability=True)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[(\"lr\", log_clf), (\"rf\", rnd_clf), (\"svc\", svm_clf)],\n",
    "    voting=\"soft\"\n",
    ")\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging and Pasting\n",
    "Different approach is to train each predictior with the same algorithm but with different training subsets. If the sampling is done with replacement, this mechanism is called bagging (short from bootstrap aggregating). If the sampling is done without replacement, then this mechanism is called pasting. In other words: both mechanism allow us to sample using many training examples with all of the predictios, but only the first mechnism allow us to feed one predictior multiple times. (with replecement - feed one predictior multiple times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.904"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(),\n",
    "    n_estimators=500,\n",
    "    max_samples=100,\n",
    "    bootstrap=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OOB score\n",
    "While aggregating, about 63% of the trainign seet is never seen by a predictor. This data is called Out-Of-Bag instances - OOB. Becouse they are not used during learning, we can use them to evaluate the model. We can also measure the score of whole ensemble by calculating the mean of all OBB scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.928"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(),\n",
    "    n_estimators=500,\n",
    "    max_samples=100,\n",
    "    bootstrap=True,\n",
    "    n_jobs=-1,\n",
    "    oob_score=True\n",
    ")\n",
    "\n",
    "bag_clf.fit(X_train, y_train)\n",
    "\n",
    "bag_clf.oob_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.904"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = bag_clf.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31216931, 0.68783069],\n",
       "       [0.39473684, 0.60526316],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00518135, 0.99481865],\n",
       "       [0.02313625, 0.97686375],\n",
       "       [0.10498688, 0.89501312],\n",
       "       [0.44297082, 0.55702918],\n",
       "       [0.06266319, 0.93733681],\n",
       "       [0.94320988, 0.05679012],\n",
       "       [0.85340314, 0.14659686],\n",
       "       [0.58823529, 0.41176471],\n",
       "       [0.06940874, 0.93059126],\n",
       "       [0.73684211, 0.26315789],\n",
       "       [0.85714286, 0.14285714],\n",
       "       [0.93830334, 0.06169666],\n",
       "       [0.07397959, 0.92602041],\n",
       "       [0.03157895, 0.96842105],\n",
       "       [0.9144385 , 0.0855615 ],\n",
       "       [0.6984127 , 0.3015873 ],\n",
       "       [0.96231156, 0.03768844],\n",
       "       [0.05744125, 0.94255875],\n",
       "       [0.285     , 0.715     ],\n",
       "       [0.87373737, 0.12626263],\n",
       "       [0.9924812 , 0.0075188 ],\n",
       "       [0.9673913 , 0.0326087 ],\n",
       "       [0.00533333, 0.99466667],\n",
       "       [0.96391753, 0.03608247],\n",
       "       [1.        , 0.        ],\n",
       "       [0.02331606, 0.97668394],\n",
       "       [0.71688312, 0.28311688],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99493671, 0.00506329],\n",
       "       [0.00537634, 0.99462366],\n",
       "       [0.06878307, 0.93121693],\n",
       "       [0.10182768, 0.89817232],\n",
       "       [0.97631579, 0.02368421],\n",
       "       [0.01574803, 0.98425197],\n",
       "       [0.5390625 , 0.4609375 ],\n",
       "       [0.01907357, 0.98092643],\n",
       "       [1.        , 0.        ],\n",
       "       [0.10512821, 0.89487179],\n",
       "       [0.33870968, 0.66129032],\n",
       "       [0.99228792, 0.00771208],\n",
       "       [0.98153034, 0.01846966],\n",
       "       [0.00280899, 0.99719101],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.06185567, 0.93814433],\n",
       "       [0.97738693, 0.02261307],\n",
       "       [0.05026455, 0.94973545],\n",
       "       [0.95918367, 0.04081633],\n",
       "       [0.83507853, 0.16492147],\n",
       "       [0.92151899, 0.07848101],\n",
       "       [0.83421053, 0.16578947],\n",
       "       [0.02077922, 0.97922078],\n",
       "       [0.08072917, 0.91927083],\n",
       "       [0.85066667, 0.14933333],\n",
       "       [0.01012658, 0.98987342],\n",
       "       [0.01554404, 0.98445596],\n",
       "       [0.04947917, 0.95052083],\n",
       "       [0.87967914, 0.12032086],\n",
       "       [0.61315789, 0.38684211],\n",
       "       [0.72292191, 0.27707809],\n",
       "       [0.99453552, 0.00546448],\n",
       "       [0.02879581, 0.97120419],\n",
       "       [0.79614325, 0.20385675],\n",
       "       [0.97668394, 0.02331606],\n",
       "       [0.99212598, 0.00787402],\n",
       "       [0.65555556, 0.34444444],\n",
       "       [0.98123324, 0.01876676],\n",
       "       [0.32911392, 0.67088608],\n",
       "       [0.31233596, 0.68766404],\n",
       "       [0.45721925, 0.54278075],\n",
       "       [0.68245125, 0.31754875],\n",
       "       [0.00498753, 0.99501247],\n",
       "       [0.33068783, 0.66931217],\n",
       "       [0.85983827, 0.14016173],\n",
       "       [1.        , 0.        ],\n",
       "       [0.04303797, 0.95696203],\n",
       "       [0.96482412, 0.03517588],\n",
       "       [0.00263158, 0.99736842],\n",
       "       [0.23453608, 0.76546392],\n",
       "       [0.16578947, 0.83421053],\n",
       "       [0.41578947, 0.58421053],\n",
       "       [0.98974359, 0.01025641],\n",
       "       [0.04255319, 0.95744681],\n",
       "       [0.65445026, 0.34554974],\n",
       "       [0.04627249, 0.95372751],\n",
       "       [0.04155844, 0.95844156],\n",
       "       [0.        , 1.        ],\n",
       "       [0.35263158, 0.64736842],\n",
       "       [1.        , 0.        ],\n",
       "       [0.0026738 , 0.9973262 ],\n",
       "       [0.06896552, 0.93103448],\n",
       "       [0.02046036, 0.97953964],\n",
       "       [0.79844961, 0.20155039],\n",
       "       [0.6835443 , 0.3164557 ],\n",
       "       [0.07608696, 0.92391304],\n",
       "       [0.9973545 , 0.0026455 ],\n",
       "       [0.35733333, 0.64266667],\n",
       "       [0.68911917, 0.31088083],\n",
       "       [0.01025641, 0.98974359],\n",
       "       [0.08997429, 0.91002571],\n",
       "       [0.45194805, 0.54805195],\n",
       "       [0.96866841, 0.03133159],\n",
       "       [0.03836317, 0.96163683],\n",
       "       [0.96455696, 0.03544304],\n",
       "       [0.41666667, 0.58333333],\n",
       "       [0.31538462, 0.68461538],\n",
       "       [0.99473684, 0.00526316],\n",
       "       [0.23157895, 0.76842105],\n",
       "       [0.88974359, 0.11025641],\n",
       "       [0.2823219 , 0.7176781 ],\n",
       "       [0.76349614, 0.23650386],\n",
       "       [0.9947644 , 0.0052356 ],\n",
       "       [0.98961039, 0.01038961],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.53403141, 0.46596859],\n",
       "       [0.99210526, 0.00789474],\n",
       "       [0.07216495, 0.92783505],\n",
       "       [0.98391421, 0.01608579],\n",
       "       [0.98004988, 0.01995012],\n",
       "       [0.99453552, 0.00546448],\n",
       "       [0.96391753, 0.03608247],\n",
       "       [0.97319035, 0.02680965],\n",
       "       [0.04347826, 0.95652174],\n",
       "       [0.91939547, 0.08060453],\n",
       "       [0.94750656, 0.05249344],\n",
       "       [0.02564103, 0.97435897],\n",
       "       [0.24933687, 0.75066313],\n",
       "       [0.84050633, 0.15949367],\n",
       "       [0.35230352, 0.64769648],\n",
       "       [0.933687  , 0.066313  ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.03457447, 0.96542553],\n",
       "       [0.79545455, 0.20454545],\n",
       "       [0.76865672, 0.23134328],\n",
       "       [0.59459459, 0.40540541],\n",
       "       [0.8857868 , 0.1142132 ],\n",
       "       [0.93617021, 0.06382979],\n",
       "       [0.12562814, 0.87437186],\n",
       "       [0.76103896, 0.23896104],\n",
       "       [0.04947917, 0.95052083],\n",
       "       [0.        , 1.        ],\n",
       "       [0.11528822, 0.88471178],\n",
       "       [0.75405405, 0.24594595],\n",
       "       [0.97631579, 0.02368421],\n",
       "       [1.        , 0.        ],\n",
       "       [0.04392765, 0.95607235],\n",
       "       [0.00824176, 0.99175824],\n",
       "       [0.07608696, 0.92391304],\n",
       "       [0.02222222, 0.97777778],\n",
       "       [0.98987342, 0.01012658],\n",
       "       [0.97668394, 0.02331606],\n",
       "       [0.89210526, 0.10789474],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.92802057, 0.07197943],\n",
       "       [0.01305483, 0.98694517],\n",
       "       [0.64155844, 0.35844156],\n",
       "       [0.37922078, 0.62077922],\n",
       "       [0.07219251, 0.92780749],\n",
       "       [0.02617801, 0.97382199],\n",
       "       [0.37692308, 0.62307692],\n",
       "       [0.99726776, 0.00273224],\n",
       "       [0.95876289, 0.04123711],\n",
       "       [0.00255754, 0.99744246],\n",
       "       [0.98938992, 0.01061008],\n",
       "       [0.06233766, 0.93766234],\n",
       "       [0.00246305, 0.99753695],\n",
       "       [0.95384615, 0.04615385],\n",
       "       [0.00813008, 0.99186992],\n",
       "       [0.00524934, 0.99475066],\n",
       "       [0.99483204, 0.00516796],\n",
       "       [0.04444444, 0.95555556],\n",
       "       [0.84432718, 0.15567282],\n",
       "       [0.9408867 , 0.0591133 ],\n",
       "       [0.04395604, 0.95604396],\n",
       "       [0.97193878, 0.02806122],\n",
       "       [0.89572193, 0.10427807],\n",
       "       [0.97319035, 0.02680965],\n",
       "       [0.01846966, 0.98153034],\n",
       "       [0.01876676, 0.98123324],\n",
       "       [1.        , 0.        ],\n",
       "       [0.26302083, 0.73697917],\n",
       "       [0.98938992, 0.01061008],\n",
       "       [0.08290155, 0.91709845],\n",
       "       [0.00506329, 0.99493671],\n",
       "       [0.98979592, 0.01020408],\n",
       "       [0.        , 1.        ],\n",
       "       [0.17232376, 0.82767624],\n",
       "       [0.9325    , 0.0675    ],\n",
       "       [0.92428198, 0.07571802],\n",
       "       [0.657289  , 0.342711  ],\n",
       "       [0.64754098, 0.35245902],\n",
       "       [0.03916449, 0.96083551],\n",
       "       [0.24033149, 0.75966851],\n",
       "       [0.98514851, 0.01485149],\n",
       "       [0.92091837, 0.07908163],\n",
       "       [0.92191436, 0.07808564],\n",
       "       [0.98191214, 0.01808786],\n",
       "       [0.05291005, 0.94708995],\n",
       "       [0.00263158, 0.99736842],\n",
       "       [0.11508951, 0.88491049],\n",
       "       [0.53684211, 0.46315789],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00498753, 0.99501247],\n",
       "       [0.95755968, 0.04244032],\n",
       "       [0.08418367, 0.91581633],\n",
       "       [0.0972973 , 0.9027027 ],\n",
       "       [0.89417989, 0.10582011],\n",
       "       [0.03278689, 0.96721311],\n",
       "       [0.36052632, 0.63947368],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.015625  , 0.984375  ],\n",
       "       [0.01315789, 0.98684211],\n",
       "       [0.92911392, 0.07088608],\n",
       "       [0.86792453, 0.13207547],\n",
       "       [0.94516971, 0.05483029],\n",
       "       [0.03269755, 0.96730245],\n",
       "       [0.0604534 , 0.9395466 ],\n",
       "       [0.9611399 , 0.0388601 ],\n",
       "       [0.11702128, 0.88297872],\n",
       "       [0.00518135, 0.99481865],\n",
       "       [0.26578947, 0.73421053],\n",
       "       [0.96174863, 0.03825137],\n",
       "       [0.81725888, 0.18274112],\n",
       "       [0.09836066, 0.90163934],\n",
       "       [0.76052632, 0.23947368],\n",
       "       [0.92525773, 0.07474227],\n",
       "       [0.13178295, 0.86821705],\n",
       "       [0.14173228, 0.85826772],\n",
       "       [0.99463807, 0.00536193],\n",
       "       [0.        , 1.        ],\n",
       "       [0.01511335, 0.98488665],\n",
       "       [0.01827676, 0.98172324],\n",
       "       [0.36315789, 0.63684211],\n",
       "       [0.82474227, 0.17525773],\n",
       "       [0.04347826, 0.95652174],\n",
       "       [0.97953964, 0.02046036],\n",
       "       [0.90765172, 0.09234828],\n",
       "       [0.00516796, 0.99483204],\n",
       "       [0.74293059, 0.25706941],\n",
       "       [0.98979592, 0.01020408],\n",
       "       [0.00524934, 0.99475066],\n",
       "       [0.98958333, 0.01041667],\n",
       "       [0.08142494, 0.91857506],\n",
       "       [0.00519481, 0.99480519],\n",
       "       [0.1193634 , 0.8806366 ],\n",
       "       [0.25271739, 0.74728261],\n",
       "       [0.84831461, 0.15168539],\n",
       "       [0.07297297, 0.92702703],\n",
       "       [0.99470899, 0.00529101],\n",
       "       [0.61229947, 0.38770053],\n",
       "       [0.09973753, 0.90026247],\n",
       "       [0.60050891, 0.39949109],\n",
       "       [0.8346056 , 0.1653944 ],\n",
       "       [0.00277778, 0.99722222],\n",
       "       [0.9950495 , 0.0049505 ],\n",
       "       [0.02894737, 0.97105263],\n",
       "       [0.        , 1.        ],\n",
       "       [0.7275    , 0.2725    ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98153034, 0.01846966],\n",
       "       [0.12634409, 0.87365591],\n",
       "       [0.7421875 , 0.2578125 ],\n",
       "       [0.13881748, 0.86118252],\n",
       "       [0.99491094, 0.00508906],\n",
       "       [0.88051948, 0.11948052],\n",
       "       [0.        , 1.        ],\n",
       "       [0.08093995, 0.91906005],\n",
       "       [0.16581633, 0.83418367],\n",
       "       [0.06371191, 0.93628809],\n",
       "       [0.        , 1.        ],\n",
       "       [0.97493036, 0.02506964],\n",
       "       [0.82978723, 0.17021277],\n",
       "       [0.21957672, 0.78042328],\n",
       "       [0.9295393 , 0.0704607 ],\n",
       "       [0.04556962, 0.95443038],\n",
       "       [0.62933333, 0.37066667],\n",
       "       [0.15526316, 0.84473684],\n",
       "       [0.95442359, 0.04557641],\n",
       "       [0.89405685, 0.10594315],\n",
       "       [0.00269542, 0.99730458],\n",
       "       [0.9375    , 0.0625    ],\n",
       "       [0.87080103, 0.12919897],\n",
       "       [0.00257069, 0.99742931],\n",
       "       [0.05804749, 0.94195251],\n",
       "       [0.99737533, 0.00262467],\n",
       "       [0.04615385, 0.95384615],\n",
       "       [0.97142857, 0.02857143],\n",
       "       [0.09186352, 0.90813648],\n",
       "       [0.8766756 , 0.1233244 ],\n",
       "       [0.99733333, 0.00266667],\n",
       "       [0.00520833, 0.99479167],\n",
       "       [0.05804749, 0.94195251],\n",
       "       [0.74210526, 0.25789474],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.70876289, 0.29123711],\n",
       "       [0.84293194, 0.15706806],\n",
       "       [0.992     , 0.008     ],\n",
       "       [0.65343915, 0.34656085],\n",
       "       [0.45876289, 0.54123711],\n",
       "       [0.02813299, 0.97186701],\n",
       "       [0.81842818, 0.18157182],\n",
       "       [0.01084011, 0.98915989],\n",
       "       [0.99739583, 0.00260417],\n",
       "       [0.74418605, 0.25581395],\n",
       "       [0.99189189, 0.00810811],\n",
       "       [1.        , 0.        ],\n",
       "       [0.81443299, 0.18556701],\n",
       "       [0.30829016, 0.69170984],\n",
       "       [0.16321244, 0.83678756],\n",
       "       [0.25454545, 0.74545455],\n",
       "       [0.        , 1.        ],\n",
       "       [0.7628866 , 0.2371134 ],\n",
       "       [0.88648649, 0.11351351],\n",
       "       [0.05483029, 0.94516971],\n",
       "       [1.        , 0.        ],\n",
       "       [0.95778364, 0.04221636],\n",
       "       [0.99197861, 0.00802139],\n",
       "       [0.00257069, 0.99742931],\n",
       "       [0.07754011, 0.92245989],\n",
       "       [0.90463215, 0.09536785],\n",
       "       [0.92366412, 0.07633588],\n",
       "       [0.99747475, 0.00252525],\n",
       "       [0.23232323, 0.76767677],\n",
       "       [0.98157895, 0.01842105],\n",
       "       [0.11548556, 0.88451444],\n",
       "       [0.94070081, 0.05929919],\n",
       "       [0.04987531, 0.95012469],\n",
       "       [0.97668394, 0.02331606],\n",
       "       [0.98704663, 0.01295337],\n",
       "       [0.98982188, 0.01017812],\n",
       "       [0.00271739, 0.99728261],\n",
       "       [0.95348837, 0.04651163],\n",
       "       [0.00265252, 0.99734748],\n",
       "       [0.07880435, 0.92119565],\n",
       "       [0.03693931, 0.96306069],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.98469388, 0.01530612],\n",
       "       [0.        , 1.        ],\n",
       "       [0.96010638, 0.03989362],\n",
       "       [0.08730159, 0.91269841],\n",
       "       [0.9947644 , 0.0052356 ],\n",
       "       [0.21105528, 0.78894472],\n",
       "       [0.01075269, 0.98924731],\n",
       "       [0.05820106, 0.94179894],\n",
       "       [0.        , 1.        ],\n",
       "       [0.80851064, 0.19148936],\n",
       "       [0.06842105, 0.93157895],\n",
       "       [0.13541667, 0.86458333],\n",
       "       [0.99489796, 0.00510204],\n",
       "       [0.92839506, 0.07160494],\n",
       "       [0.24020888, 0.75979112],\n",
       "       [0.94      , 0.06      ],\n",
       "       [0.04975124, 0.95024876],\n",
       "       [0.09462916, 0.90537084],\n",
       "       [0.99744246, 0.00255754],\n",
       "       [0.89487179, 0.10512821],\n",
       "       [0.58157895, 0.41842105],\n",
       "       [0.87037037, 0.12962963],\n",
       "       [0.99445983, 0.00554017],\n",
       "       [0.03234501, 0.96765499],\n",
       "       [0.97142857, 0.02857143],\n",
       "       [0.03856041, 0.96143959],\n",
       "       [0.15710723, 0.84289277],\n",
       "       [0.91935484, 0.08064516],\n",
       "       [1.        , 0.        ],\n",
       "       [0.09308511, 0.90691489],\n",
       "       [0.6997319 , 0.3002681 ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.oob_decision_function_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b7fdb54b42d75f7dc4bc7211c14a537c22f55fe700ff72c130752bbe38f9a9cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
