{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning and Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifiers\n",
    "These classifiers constist of multiple models. Their predictions are compared and the final predicition is the most common one (<i>hard voting classifier</i>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;, LogisticRegression()),\n",
       "                             (&#x27;rf&#x27;, RandomForestClassifier()), (&#x27;svc&#x27;, SVC())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;, LogisticRegression()),\n",
       "                             (&#x27;rf&#x27;, RandomForestClassifier()), (&#x27;svc&#x27;, SVC())])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>svc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression()),\n",
       "                             ('rf', RandomForestClassifier()), ('svc', SVC())])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[(\"lr\", log_clf), (\"rf\", rnd_clf), (\"svc\", svm_clf)],\n",
    "    voting=\"hard\"\n",
    ")\n",
    "\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "RandomForestClassifier 0.888\n",
      "SVC 0.896\n",
      "VotingClassifier 0.904\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If each classifier uses predict_proba() method, we can use <i>soft voting</i>. Prediction will be done using the probabilities values - bigger probabilities will have bigger weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "RandomForestClassifier 0.896\n",
      "SVC 0.896\n",
      "VotingClassifier 0.92\n"
     ]
    }
   ],
   "source": [
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC(probability=True)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[(\"lr\", log_clf), (\"rf\", rnd_clf), (\"svc\", svm_clf)],\n",
    "    voting=\"soft\"\n",
    ")\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging and Pasting\n",
    "Different approach is to train each predictior with the same algorithm but with different training subsets. If the sampling is done with replacement, this mechanism is called bagging (short from bootstrap aggregating). If the sampling is done without replacement, then this mechanism is called pasting. In other words: both mechanism allow us to sample using many training examples with all of the predictios, but only the first mechnism allow us to feed one predictior multiple times. (with replecement - feed one predictior multiple times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.912"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(),\n",
    "    n_estimators=500,\n",
    "    max_samples=100,\n",
    "    bootstrap=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OOB score\n",
    "While aggregating, about 63% of the trainign seet is never seen by a predictor. This data is called Out-Of-Bag instances - OOB. Becouse they are not used during learning, we can use them to evaluate the model. We can also measure the score of whole ensemble by calculating the mean of all OBB scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9226666666666666"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(),\n",
    "    n_estimators=500,\n",
    "    max_samples=100,\n",
    "    bootstrap=True,\n",
    "    n_jobs=-1,\n",
    "    oob_score=True\n",
    ")\n",
    "\n",
    "bag_clf.fit(X_train, y_train)\n",
    "\n",
    "bag_clf.oob_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.912"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = bag_clf.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.34351145, 0.65648855],\n",
       "       [0.43243243, 0.56756757],\n",
       "       [0.99746193, 0.00253807],\n",
       "       [0.01044386, 0.98955614],\n",
       "       [0.0230179 , 0.9769821 ],\n",
       "       [0.09408602, 0.90591398],\n",
       "       [0.35433071, 0.64566929],\n",
       "       [0.06185567, 0.93814433],\n",
       "       [0.95478723, 0.04521277],\n",
       "       [0.81481481, 0.18518519],\n",
       "       [0.56410256, 0.43589744],\n",
       "       [0.05319149, 0.94680851],\n",
       "       [0.74666667, 0.25333333],\n",
       "       [0.87598945, 0.12401055],\n",
       "       [0.91644909, 0.08355091],\n",
       "       [0.08521303, 0.91478697],\n",
       "       [0.02072539, 0.97927461],\n",
       "       [0.92875318, 0.07124682],\n",
       "       [0.6167979 , 0.3832021 ],\n",
       "       [0.9673913 , 0.0326087 ],\n",
       "       [0.04255319, 0.95744681],\n",
       "       [0.22727273, 0.77272727],\n",
       "       [0.86885246, 0.13114754],\n",
       "       [0.99726027, 0.00273973],\n",
       "       [0.94897959, 0.05102041],\n",
       "       [0.00512821, 0.99487179],\n",
       "       [0.96062992, 0.03937008],\n",
       "       [1.        , 0.        ],\n",
       "       [0.02088773, 0.97911227],\n",
       "       [0.73643411, 0.26356589],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00779221, 0.99220779],\n",
       "       [0.07506702, 0.92493298],\n",
       "       [0.07219251, 0.92780749],\n",
       "       [0.97680412, 0.02319588],\n",
       "       [0.02150538, 0.97849462],\n",
       "       [0.56684492, 0.43315508],\n",
       "       [0.01558442, 0.98441558],\n",
       "       [0.9974359 , 0.0025641 ],\n",
       "       [0.08762887, 0.91237113],\n",
       "       [0.35641026, 0.64358974],\n",
       "       [0.99230769, 0.00769231],\n",
       "       [0.97674419, 0.02325581],\n",
       "       [0.01578947, 0.98421053],\n",
       "       [1.        , 0.        ],\n",
       "       [0.99736148, 0.00263852],\n",
       "       [0.03166227, 0.96833773],\n",
       "       [0.96866841, 0.03133159],\n",
       "       [0.02791878, 0.97208122],\n",
       "       [0.97860963, 0.02139037],\n",
       "       [0.84130982, 0.15869018],\n",
       "       [0.95174263, 0.04825737],\n",
       "       [0.80890052, 0.19109948],\n",
       "       [0.0237467 , 0.9762533 ],\n",
       "       [0.11924119, 0.88075881],\n",
       "       [0.80839895, 0.19160105],\n",
       "       [0.0212766 , 0.9787234 ],\n",
       "       [0.024     , 0.976     ],\n",
       "       [0.0492228 , 0.9507772 ],\n",
       "       [0.83023873, 0.16976127],\n",
       "       [0.60526316, 0.39473684],\n",
       "       [0.75321337, 0.24678663],\n",
       "       [0.98984772, 0.01015228],\n",
       "       [0.0177665 , 0.9822335 ],\n",
       "       [0.7849162 , 0.2150838 ],\n",
       "       [0.97229219, 0.02770781],\n",
       "       [0.99473684, 0.00526316],\n",
       "       [0.63846154, 0.36153846],\n",
       "       [0.97429306, 0.02570694],\n",
       "       [0.35526316, 0.64473684],\n",
       "       [0.3368984 , 0.6631016 ],\n",
       "       [0.44      , 0.56      ],\n",
       "       [0.64041995, 0.35958005],\n",
       "       [0.00511509, 0.99488491],\n",
       "       [0.33942559, 0.66057441],\n",
       "       [0.88250653, 0.11749347],\n",
       "       [0.99730458, 0.00269542],\n",
       "       [0.03038674, 0.96961326],\n",
       "       [0.9403794 , 0.0596206 ],\n",
       "       [0.00775194, 0.99224806],\n",
       "       [0.20887728, 0.79112272],\n",
       "       [0.13279133, 0.86720867],\n",
       "       [0.45901639, 0.54098361],\n",
       "       [0.99498747, 0.00501253],\n",
       "       [0.02887139, 0.97112861],\n",
       "       [0.59782609, 0.40217391],\n",
       "       [0.06361323, 0.93638677],\n",
       "       [0.02387268, 0.97612732],\n",
       "       [0.        , 1.        ],\n",
       "       [0.32741117, 0.67258883],\n",
       "       [0.99750623, 0.00249377],\n",
       "       [0.00795756, 0.99204244],\n",
       "       [0.05927835, 0.94072165],\n",
       "       [0.01503759, 0.98496241],\n",
       "       [0.77952756, 0.22047244],\n",
       "       [0.68421053, 0.31578947],\n",
       "       [0.07142857, 0.92857143],\n",
       "       [0.9974359 , 0.0025641 ],\n",
       "       [0.36147757, 0.63852243],\n",
       "       [0.71105528, 0.28894472],\n",
       "       [0.00262467, 0.99737533],\n",
       "       [0.08152174, 0.91847826],\n",
       "       [0.40673575, 0.59326425],\n",
       "       [0.97662338, 0.02337662],\n",
       "       [0.04834606, 0.95165394],\n",
       "       [0.97043011, 0.02956989],\n",
       "       [0.43734015, 0.56265985],\n",
       "       [0.29473684, 0.70526316],\n",
       "       [0.99734043, 0.00265957],\n",
       "       [0.21750663, 0.78249337],\n",
       "       [0.86015831, 0.13984169],\n",
       "       [0.26683938, 0.73316062],\n",
       "       [0.77040816, 0.22959184],\n",
       "       [0.99222798, 0.00777202],\n",
       "       [0.99460916, 0.00539084],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00259067, 0.99740933],\n",
       "       [0.47848101, 0.52151899],\n",
       "       [0.99473684, 0.00526316],\n",
       "       [0.07874016, 0.92125984],\n",
       "       [0.99469496, 0.00530504],\n",
       "       [0.96505376, 0.03494624],\n",
       "       [1.        , 0.        ],\n",
       "       [0.95211268, 0.04788732],\n",
       "       [0.99463807, 0.00536193],\n",
       "       [0.04639175, 0.95360825],\n",
       "       [0.9507772 , 0.0492228 ],\n",
       "       [0.98449612, 0.01550388],\n",
       "       [0.02253521, 0.97746479],\n",
       "       [0.22279793, 0.77720207],\n",
       "       [0.90909091, 0.09090909],\n",
       "       [0.38931298, 0.61068702],\n",
       "       [0.92631579, 0.07368421],\n",
       "       [0.01033592, 0.98966408],\n",
       "       [0.04696133, 0.95303867],\n",
       "       [0.78688525, 0.21311475],\n",
       "       [0.734375  , 0.265625  ],\n",
       "       [0.54447439, 0.45552561],\n",
       "       [0.88832487, 0.11167513],\n",
       "       [0.92950392, 0.07049608],\n",
       "       [0.10880829, 0.89119171],\n",
       "       [0.84382872, 0.15617128],\n",
       "       [0.05223881, 0.94776119],\n",
       "       [0.01072386, 0.98927614],\n",
       "       [0.11202186, 0.88797814],\n",
       "       [0.76590331, 0.23409669],\n",
       "       [0.96124031, 0.03875969],\n",
       "       [0.99737533, 0.00262467],\n",
       "       [0.03926702, 0.96073298],\n",
       "       [0.01322751, 0.98677249],\n",
       "       [0.05852417, 0.94147583],\n",
       "       [0.01861702, 0.98138298],\n",
       "       [0.99208443, 0.00791557],\n",
       "       [0.984375  , 0.015625  ],\n",
       "       [0.87297297, 0.12702703],\n",
       "       [0.9921466 , 0.0078534 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.90231362, 0.09768638],\n",
       "       [0.01101928, 0.98898072],\n",
       "       [0.66080402, 0.33919598],\n",
       "       [0.32552083, 0.67447917],\n",
       "       [0.05426357, 0.94573643],\n",
       "       [0.02088773, 0.97911227],\n",
       "       [0.33157895, 0.66842105],\n",
       "       [0.98921833, 0.01078167],\n",
       "       [0.96495957, 0.03504043],\n",
       "       [0.00266667, 0.99733333],\n",
       "       [0.9821883 , 0.0178117 ],\n",
       "       [0.05263158, 0.94736842],\n",
       "       [0.00767263, 0.99232737],\n",
       "       [0.95396419, 0.04603581],\n",
       "       [0.02319588, 0.97680412],\n",
       "       [0.00255754, 0.99744246],\n",
       "       [1.        , 0.        ],\n",
       "       [0.02387268, 0.97612732],\n",
       "       [0.79895561, 0.20104439],\n",
       "       [0.96256684, 0.03743316],\n",
       "       [0.03713528, 0.96286472],\n",
       "       [0.97606383, 0.02393617],\n",
       "       [0.92564103, 0.07435897],\n",
       "       [0.98730964, 0.01269036],\n",
       "       [0.02025316, 0.97974684],\n",
       "       [0.01808786, 0.98191214],\n",
       "       [0.99466667, 0.00533333],\n",
       "       [0.21715818, 0.78284182],\n",
       "       [0.98704663, 0.01295337],\n",
       "       [0.08994709, 0.91005291],\n",
       "       [0.01745636, 0.98254364],\n",
       "       [0.98704663, 0.01295337],\n",
       "       [0.        , 1.        ],\n",
       "       [0.22865014, 0.77134986],\n",
       "       [0.89973615, 0.10026385],\n",
       "       [0.92592593, 0.07407407],\n",
       "       [0.61518325, 0.38481675],\n",
       "       [0.74870466, 0.25129534],\n",
       "       [0.04060914, 0.95939086],\n",
       "       [0.25445293, 0.74554707],\n",
       "       [0.98666667, 0.01333333],\n",
       "       [0.89717224, 0.10282776],\n",
       "       [0.93048128, 0.06951872],\n",
       "       [0.97382199, 0.02617801],\n",
       "       [0.08136483, 0.91863517],\n",
       "       [0.01362398, 0.98637602],\n",
       "       [0.09296482, 0.90703518],\n",
       "       [0.48684211, 0.51315789],\n",
       "       [0.        , 1.        ],\n",
       "       [0.01804124, 0.98195876],\n",
       "       [0.96891192, 0.03108808],\n",
       "       [0.07692308, 0.92307692],\n",
       "       [0.09319899, 0.90680101],\n",
       "       [0.89033943, 0.10966057],\n",
       "       [0.05412371, 0.94587629],\n",
       "       [0.42133333, 0.57866667],\n",
       "       [0.0104712 , 0.9895288 ],\n",
       "       [0.99744898, 0.00255102],\n",
       "       [0.01822917, 0.98177083],\n",
       "       [0.00821918, 0.99178082],\n",
       "       [0.8938992 , 0.1061008 ],\n",
       "       [0.88833747, 0.11166253],\n",
       "       [0.98108108, 0.01891892],\n",
       "       [0.02849741, 0.97150259],\n",
       "       [0.06870229, 0.93129771],\n",
       "       [0.96495957, 0.03504043],\n",
       "       [0.14435696, 0.85564304],\n",
       "       [0.00536193, 0.99463807],\n",
       "       [0.24675325, 0.75324675],\n",
       "       [0.95856354, 0.04143646],\n",
       "       [0.8359375 , 0.1640625 ],\n",
       "       [0.0925    , 0.9075    ],\n",
       "       [0.74686717, 0.25313283],\n",
       "       [0.94764398, 0.05235602],\n",
       "       [0.2010582 , 0.7989418 ],\n",
       "       [0.17801047, 0.82198953],\n",
       "       [0.99484536, 0.00515464],\n",
       "       [0.        , 1.        ],\n",
       "       [0.01808786, 0.98191214],\n",
       "       [0.024     , 0.976     ],\n",
       "       [0.32887701, 0.67112299],\n",
       "       [0.88947368, 0.11052632],\n",
       "       [0.05249344, 0.94750656],\n",
       "       [0.98477157, 0.01522843],\n",
       "       [0.8766756 , 0.1233244 ],\n",
       "       [0.01038961, 0.98961039],\n",
       "       [0.79259259, 0.20740741],\n",
       "       [0.99457995, 0.00542005],\n",
       "       [0.00522193, 0.99477807],\n",
       "       [0.992     , 0.008     ],\n",
       "       [0.0625    , 0.9375    ],\n",
       "       [0.00795756, 0.99204244],\n",
       "       [0.12403101, 0.87596899],\n",
       "       [0.23809524, 0.76190476],\n",
       "       [0.83507853, 0.16492147],\n",
       "       [0.06020942, 0.93979058],\n",
       "       [0.99740933, 0.00259067],\n",
       "       [0.66578249, 0.33421751],\n",
       "       [0.11702128, 0.88297872],\n",
       "       [0.69354839, 0.30645161],\n",
       "       [0.84880637, 0.15119363],\n",
       "       [0.01049869, 0.98950131],\n",
       "       [0.99481865, 0.00518135],\n",
       "       [0.01799486, 0.98200514],\n",
       "       [0.        , 1.        ],\n",
       "       [0.72351421, 0.27648579],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99457995, 0.00542005],\n",
       "       [0.09433962, 0.90566038],\n",
       "       [0.78947368, 0.21052632],\n",
       "       [0.13720317, 0.86279683],\n",
       "       [0.99749373, 0.00250627],\n",
       "       [0.85675676, 0.14324324],\n",
       "       [0.00995025, 0.99004975],\n",
       "       [0.07859079, 0.92140921],\n",
       "       [0.13350785, 0.86649215],\n",
       "       [0.09814324, 0.90185676],\n",
       "       [0.00261097, 0.99738903],\n",
       "       [0.96514745, 0.03485255],\n",
       "       [0.8725    , 0.1275    ],\n",
       "       [0.19321149, 0.80678851],\n",
       "       [0.91494845, 0.08505155],\n",
       "       [0.07936508, 0.92063492],\n",
       "       [0.61479592, 0.38520408],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.94565217, 0.05434783],\n",
       "       [0.87798408, 0.12201592],\n",
       "       [0.00520833, 0.99479167],\n",
       "       [0.92746114, 0.07253886],\n",
       "       [0.91489362, 0.08510638],\n",
       "       [0.0052356 , 0.9947644 ],\n",
       "       [0.05384615, 0.94615385],\n",
       "       [0.99745547, 0.00254453],\n",
       "       [0.02902375, 0.97097625],\n",
       "       [0.9870801 , 0.0129199 ],\n",
       "       [0.09669211, 0.90330789],\n",
       "       [0.9057072 , 0.0942928 ],\n",
       "       [0.9973545 , 0.0026455 ],\n",
       "       [0.00787402, 0.99212598],\n",
       "       [0.0474934 , 0.9525066 ],\n",
       "       [0.68475452, 0.31524548],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99734748, 0.00265252],\n",
       "       [0.65343915, 0.34656085],\n",
       "       [0.86052632, 0.13947368],\n",
       "       [0.99452055, 0.00547945],\n",
       "       [0.74540682, 0.25459318],\n",
       "       [0.47184987, 0.52815013],\n",
       "       [0.02835052, 0.97164948],\n",
       "       [0.81842818, 0.18157182],\n",
       "       [0.01049869, 0.98950131],\n",
       "       [0.99731903, 0.00268097],\n",
       "       [0.74484536, 0.25515464],\n",
       "       [0.99230769, 0.00769231],\n",
       "       [0.99731183, 0.00268817],\n",
       "       [0.83375959, 0.16624041],\n",
       "       [0.33165829, 0.66834171],\n",
       "       [0.13212435, 0.86787565],\n",
       "       [0.22074468, 0.77925532],\n",
       "       [0.00250627, 0.99749373],\n",
       "       [0.73589744, 0.26410256],\n",
       "       [0.87338501, 0.12661499],\n",
       "       [0.03598972, 0.96401028],\n",
       "       [0.99175824, 0.00824176],\n",
       "       [0.98191214, 0.01808786],\n",
       "       [0.99202128, 0.00797872],\n",
       "       [0.00537634, 0.99462366],\n",
       "       [0.07552083, 0.92447917],\n",
       "       [0.95710456, 0.04289544],\n",
       "       [0.93667546, 0.06332454],\n",
       "       [0.99007444, 0.00992556],\n",
       "       [0.21446384, 0.78553616],\n",
       "       [0.99466667, 0.00533333],\n",
       "       [0.13477089, 0.86522911],\n",
       "       [0.94444444, 0.05555556],\n",
       "       [0.06684492, 0.93315508],\n",
       "       [0.9822335 , 0.0177665 ],\n",
       "       [0.99468085, 0.00531915],\n",
       "       [0.99236641, 0.00763359],\n",
       "       [0.00261097, 0.99738903],\n",
       "       [0.95026178, 0.04973822],\n",
       "       [0.01084011, 0.98915989],\n",
       "       [0.04909561, 0.95090439],\n",
       "       [0.03957784, 0.96042216],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99748111, 0.00251889],\n",
       "       [0.98730964, 0.01269036],\n",
       "       [0.        , 1.        ],\n",
       "       [0.96596859, 0.03403141],\n",
       "       [0.09367089, 0.90632911],\n",
       "       [0.99449036, 0.00550964],\n",
       "       [0.18956044, 0.81043956],\n",
       "       [0.00260417, 0.99739583],\n",
       "       [0.08312343, 0.91687657],\n",
       "       [0.00515464, 0.99484536],\n",
       "       [0.83684211, 0.16315789],\n",
       "       [0.06958763, 0.93041237],\n",
       "       [0.11959288, 0.88040712],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96428571, 0.03571429],\n",
       "       [0.20734908, 0.79265092],\n",
       "       [0.93198992, 0.06801008],\n",
       "       [0.04960836, 0.95039164],\n",
       "       [0.09840426, 0.90159574],\n",
       "       [1.        , 0.        ],\n",
       "       [0.93401015, 0.06598985],\n",
       "       [0.5257732 , 0.4742268 ],\n",
       "       [0.87172775, 0.12827225],\n",
       "       [1.        , 0.        ],\n",
       "       [0.03947368, 0.96052632],\n",
       "       [0.9787234 , 0.0212766 ],\n",
       "       [0.04488778, 0.95511222],\n",
       "       [0.13192612, 0.86807388],\n",
       "       [0.92631579, 0.07368421],\n",
       "       [0.99746193, 0.00253807],\n",
       "       [0.08060453, 0.91939547],\n",
       "       [0.68463612, 0.31536388]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.oob_decision_function_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Patches and Random Subspaces\n",
    "Sampling training examples and features - Random Patches Method\n",
    "\n",
    "Sampling only features - Random Subspaces Method (Done by setting bootstrap=False, max_samples=1.0 and bootstrap_features=True, max_features lower than 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.53237933, 0.23699324, 0.21249745, 0.98607904, 0.98180838,\n",
       "       0.88764525, 0.01156969, 0.03342178, 0.05328147, 0.06843063,\n",
       "       0.98607904, 0.01156969, 0.92726734, 0.86190559, 0.98503549,\n",
       "       0.01156969, 0.01156969, 0.95253994, 0.85542725, 0.08510785,\n",
       "       0.01156969, 0.99713512, 0.55335608, 0.00171878, 0.10089583,\n",
       "       0.1554341 , 0.95638781, 0.01156969, 0.93080494, 0.0115991 ,\n",
       "       0.94215743, 0.98607904, 0.23812511, 0.01183423, 0.98572691,\n",
       "       0.07914256, 0.02175827, 0.98572691, 0.98578486, 0.96884642,\n",
       "       0.30665759, 0.93073188, 0.29628786, 0.23807645, 0.0115991 ,\n",
       "       0.1373378 , 0.73928203, 0.55085862, 0.98577135, 0.55347355,\n",
       "       0.93105818, 0.98607904, 0.01156969, 0.0115991 , 0.82938221,\n",
       "       0.01183423, 0.90346889, 0.98584456, 0.0115991 , 0.97483181,\n",
       "       0.01156969, 0.83398729, 0.98121195, 0.01156969, 0.97704034,\n",
       "       0.01183423, 0.07406762, 0.16383095, 0.01156969, 0.99913512,\n",
       "       0.42512969, 0.01907925, 0.84472355, 0.63447917, 0.01156969,\n",
       "       0.01156969, 0.98607904, 0.98607904, 0.0115991 , 0.11424668,\n",
       "       0.99296009, 0.98535728, 0.93355293, 0.07464491, 0.92680494,\n",
       "       0.81712452, 0.64737664, 0.03836039, 0.98197789, 0.98578486,\n",
       "       0.98607904, 0.0115991 , 0.03186622, 0.01183423, 0.01356969,\n",
       "       0.96863124, 0.0115991 , 0.45375919, 0.19702784, 0.98607904,\n",
       "       0.0115991 , 0.99170226, 0.94215743, 0.07254971, 0.04637155,\n",
       "       0.01156969, 0.00754265, 0.19486446, 0.56531064, 0.97903549,\n",
       "       0.47010218, 0.13669691, 0.0115991 , 0.98535728, 0.57440398,\n",
       "       0.0345685 , 0.01183423, 0.01156969, 0.00754265, 0.94336634,\n",
       "       0.98572691, 0.98578486, 0.14481537, 0.06270471, 0.17859608])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rnd_clf = RandomForestRegressor(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n",
    "rnd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees\n",
    "In each node the split is done randomly, not by looking the best threshold - Extremely Random Trees (Extra Trees)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm) 0.09238128154723367\n",
      "sepal width (cm) 0.022376154674010943\n",
      "petal length (cm) 0.44732226253629553\n",
      "petal width (cm) 0.4379203012424599\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, n_jobs=-1)\n",
    "rnd_clf.fit(iris[\"data\"], iris[\"target\"])\n",
    "\n",
    "for name, score in zip(iris[\"feature_names\"], rnd_clf.feature_importances_):\n",
    "    print(name, score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b7fdb54b42d75f7dc4bc7211c14a537c22f55fe700ff72c130752bbe38f9a9cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
